---
title: "Kira Plastinina"
author: "Katheu"
date: "7/9/2021"
output: html_document
---

## Defining the Question

Kira Plastinina is a Russian brand that is sold through a defunct chain of retail stores in Russia, Ukraine, Kazakhstan, Belarus, China, Philippines, and Armenia. The brand’s Sales and Marketing team would like to understand their customer’s behavior from data that they have collected over the past year. More specifically, they would like to learn the characteristics of customer groups.

## Metric of success

To perform clustering stating insights drawn from my analysis and visualizations.
Upon implementation, provide comparisons between the approaches i.e. K-Means clustering vs Hierarchical clustering highlighting the strengths and limitations of each approach in the context of my analysis.

## Understanding the Context

Customer behavior analysis is an observation of how customers  interact with your website. Studying the customer behavior allows you to answer questions such as how marketing campaigns can be improved to effectively influence the customer's behavior. There are four types of consumer buying behavior;

* Complex buying behavior
* Dissonance-reducing buying behavior
* Habitual buying behavior
* Varity seeking behavior

## Experimental Design

* Problem Definition
* Data Sourcing
* Check the Data
* Perform Data Cleaning
* Perform Exploratory Data Analysis
* Implement the Solution
* Challenge the Solution
* Follow up Questions

## Data Relevance

* The dataset consists of 10 numerical and 8 categorical attributes. The 'Revenue' attribute can be used as the class label.
* "Administrative", "Administrative Duration", "Informational", "Informational Duration", "Product Related" and "Product Related Duration" represents the number of different types of pages visited by the visitor in that session and total time spent in each of these page categories. The values of these features are derived from the URL information of the pages visited by the user and updated in real-time when a user takes an action, e.g. moving from one page to another. 
* The "Bounce Rate", "Exit Rate" and "Page Value" features represent the metrics measured by "Google Analytics" for each page in the e-commerce site. 
* The value of the "Bounce Rate" feature for a web page refers to the percentage of visitors who enter the site from that page and then leave ("bounce") without triggering any other requests to the analytics server during that session. 
* The value of the "Exit Rate" feature for a specific web page is calculated as for all pageviews to the page, the percentage that was the last in the session.
* The "Page Value" feature represents the average value for a web page that a user visited before completing an e-commerce transaction. 
The "Special Day" feature indicates the closeness of the site visiting time to a specific special day (e.g. Mother’s Day, Valentine's Day) in which the sessions are more likely to be finalized with the transaction. The value of this attribute is determined by considering the dynamics of e-commerce such as the duration between the order date and delivery date. For example, for Valentina’s day, this value takes a nonzero value between February 2 and February 12, zero before and after this date unless it is close to another special day, and its maximum value of 1 on February 8. 
The dataset also includes the operating system, browser, region, traffic type, visitor type as returning or new visitor, a Boolean value indicating whether the date of the visit is weekend, and month of the year.

## Loading the Dataset

```{r}
kira <- read.csv('http://bit.ly/EcommerceCustomersDataset')
```

### Previewing the top of our dataset
```{r}
head(kira)
```
### Previewing the bottom of our dataset
```{r}
tail(kira)
```
## Data Exploration

```{r}
View(kira)
```

Checking the structure of our dataset.

```{r}
str(kira)
```
Our dataframe has 12330 rows and 18 columns. 2 of which have a logical data type, 2 have a character data type, 7 are of the integers data type and the other 7 are numerical.

Checking the summary of our dataframe kira.

```{r}
summary(kira)
```
## Data Cleaning

Finding the total missing values in our dataset.
```{r}
colSums(is.na(kira))
```
```{r}
sum(is.na(kira))
```
There are 112 missing values in total. We will drop these.
```{r}
kira <- na.omit(kira)
```

```{r}
library(na.tools)
anyNA(kira)
```
Checking for duplicated rows.
```{r}
kira[duplicated(kira),]
```
There are 117 duplicated rows in this dataset. We shall drop these so as to achieve better results.

```{r}
kira_p <- kira[!duplicated(kira), ]
```

Confirming the duplicated rows have been dropped.

```{r}
kira_p[duplicated(kira_p),]
```
Let's fix the structure of this dataset

```{r}
kira_p$Revenue <- gsub(FALSE, 0, kira_p$Revenue)
kira_p$Revenue <- gsub(TRUE, 1, kira_p$Revenue)
kira_p$Weekend <- gsub(TRUE, 1, kira_p$Weekend)
kira_p$Weekend <- gsub(FALSE, 0, kira_p$Weekend)
```


```{r}
kira_p$Month <- factor(kira_p$Month, levels = c("Feb", "Mar", "May", "June", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"), ordered = TRUE)
kira_p$OperatingSystems <- factor(kira_p$OperatingSystems)
kira_p$Browser <- factor(kira_p$Browser)
kira_p$Region <- factor(kira_p$Region)
kira_p$TrafficType <- factor(kira_p$TrafficType)
kira_p$VisitorType <- factor(kira_p$VisitorType)
kira_p$Revenue <- factor(kira_p$Revenue)
kira_p$Weekend <- factor(kira_p$Weekend)
```

Confirming the structure is okay to work with.

```{r}
str(kira_p)
```



Checking for outliers

```{r}
boxplot(kira_p$Administrative,
        main ="Administrative Page Visits",
        col = "orange",
        border  = 'brown',
        horizontal = TRUE,
        notch = TRUE)
#There are some outliers in the administrative column.
```

```{r}
boxplot(kira_p$Administrative_Duration,
        main ="Time spent on the Administrative page",
        col = "orange",
        border  = 'brown',
        horizontal = TRUE,
        notch = TRUE)
```

```{r}
boxplot(kira_p$Informational,
        main ="Informational page Visits",
        col = "orange",
        border  = 'brown',
        horizontal = TRUE,
        notch = TRUE)
```


```{r}
boxplot(kira_p$Informational_Duration,
        main ="Time Spent on Duration page",
        col = "orange",
        border  = 'brown',
        horizontal = TRUE,
        notch = TRUE)
```
```{r}
boxplot(kira_p$ProductRelated,
        main ="Product Related Page Visits",
        col = "orange",
        border  = 'brown',
        horizontal = TRUE,
        notch = TRUE)
```

```{r}
boxplot(kira_p$BounceRates,
        main ="Bounce Rate",
        col = "orange",
        border  = 'brown',
        horizontal = TRUE,
        notch = TRUE)
```
```{r}
boxplot(kira_p$ExitRates,
        main ="Exit Rates",
        col = "orange",
        border  = 'brown',
        horizontal = TRUE,
        notch = TRUE)
```

```{r}
boxplot(kira_p$PageValues,
        main ="Page values",
        col = "orange",
        border  = 'brown',
        horizontal = TRUE,
        notch = TRUE)
```
```{r}
boxplot(kira_p$SpecialDay,
        main ="Special Day",
        col = "orange",
        border  = 'brown',
        horizontal = TRUE,
        notch = TRUE)
```

## Exploratory Data Analysis

### Univariate Analysis
#### Meaasures of Central Tendency

Finding the mean of our numeric columns

```{r}
colMeans(kira_p[sapply(kira_p,is.numeric)])


```
Finding the median of our numeric columns.

```{r}
admin_median <- median(kira_p$Administrative)
admin_time <- median(kira_p$Administrative_Duration)
info_median <- median(kira_p$Informational)
info_time <- median(kira_p$Informational_Duration)
product_median <- median(kira_p$ProductRelated)
product_time <- median(kira_p$ProductRelated_Duration)
bounce_median <- median(kira_p$BounceRates)
exit_median <- median(kira_p$ExitRates)
page_median <- median(kira_p$PageValues)
specialday_median <- median(kira_p$SpecialDay)

admin_median
admin_time
info_median 
info_time 
product_median 
product_time 
bounce_median 
exit_median
page_median
specialday_median 
```
Finding the mode of our numeric columns. Creating the mode function.

```{r}
getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]}
```

```{r}
getmode(kira_p$Administrative)
getmode(kira_p$Administrative_Duration)
getmode(kira_p$Informational)
getmode(kira_p$Informational_Duration)
getmode(kira_p$ProductRelated)
getmode(kira_p$ProductRelated_Duration)
getmode(kira_p$BounceRates)
getmode(kira_p$ExitRates)
getmode(kira_p$PageValues)
getmode(kira_p$SpecialDay)
```
Finding the range in our columns. The results will give us the minimum and maximum values in our numeric columns.

```{r}
range(kira_p$Administrative)
range(kira_p$Administrative_Duration)
range(kira_p$Informational)
range(kira_p$Informational_Duration)
range(kira_p$ProductRelated)
range(kira_p$ProductRelated_Duration)
range(kira_p$BounceRates)
range(kira_p$ExitRates)
range(kira_p$PageValues)
range(kira_p$SpecialDay)

```
Getting the Quantiles in our numeric columns.

```{r}
quantile(kira_p$Administrative)
quantile(kira_p$Administrative_Duration)
quantile(kira_p$Informational)
quantile(kira_p$Informational_Duration)
quantile(kira_p$ProductRelated)
quantile(kira_p$ProductRelated_Duration)
quantile(kira_p$BounceRates)
quantile(kira_p$ExitRates)
quantile(kira_p$PageValues)
quantile(kira_p$SpecialDay)
```
Finding the variance of the numeric columns. This shows how the data values are dispersed around the mean.

```{r}
var(kira_p$Administrative)
var(kira_p$Administrative_Duration)
var(kira_p$Informational)
var(kira_p$Informational_Duration)
var(kira_p$ProductRelated)
var(kira_p$ProductRelated_Duration)
var(kira_p$BounceRates)
var(kira_p$ExitRates)
var(kira_p$PageValues)
var(kira_p$SpecialDay)
```
Finding the standard deviation of our numeric columns
```{r}
sd(kira_p$Administrative)
sd(kira_p$Administrative_Duration)
sd(kira_p$Informational)
sd(kira_p$Informational_Duration)
sd(kira_p$ProductRelated)
sd(kira_p$ProductRelated_Duration)
sd(kira_p$BounceRates)
sd(kira_p$ExitRates)
sd(kira_p$PageValues)
sd(kira_p$SpecialDay)
```

#### Descriptive Analysis

```{r}
table(kira_p$Revenue)
table(kira_p$Weekend)
table(kira_p$VisitorType)
table(kira_p$TrafficType)
table(kira_p$Region)
table(kira_p$Browser)
table(kira_p$OperatingSystems)
table(kira_p$Month)
```
#### Histograms

```{r}
hist(kira_p$Administrative, col  = "yellow")

```
```{r}
hist(kira_p$BounceRates, col  = "purple")

```
```{r}
hist(kira_p$Informational, col  = "green")

```
```{r}
hist(kira_p$ProductRelated, col  = "orange")

```
```{r}
hist(kira_p$ExitRates, col  = "red")

```
```{r}
hist(kira_p$PageValues, col  = "violet")

```
```{r}
hist(kira_p$SpecialDay, col  = "blue")

```

### Bivariate Analysis

#### Correlation

```{r}
library(corrplot)

correlation <- cor(kira_p[,c(1:10)])
corrplot(correlation, method = "square", type = "lower", diag = TRUE)
```

#### Covariance

Covariance is a statistical representation of the degree to which two variables vary together.

```{r}
cov(kira_p$Administrative, kira_p$BounceRates)
cov(kira_p$Informational, kira_p$ExitRates)
cov(kira_p$ProductRelated, kira_p$BounceRates)
cov(kira_p$BounceRates, kira_p$ExitRates)
cov(kira_p$Informational, kira_p$BounceRates)
cov(kira_p$Administrative, kira_p$ExitRates)
```
There is a weak negative relationship between most of our variables.

Plotting a ggplot to show the relationship between the Exit and Bounce Rates.
```{r}
library(ggplot2)

options(repr.plot.width = 8, repr.plot.height = 5)
ggplot(data = kira_p, mapping = aes(x = BounceRates, y = ExitRates)) + geom_point(mapping = aes(color = Revenue)) + geom_smooth(se = TRUE, alpha = 0.5) + theme_light() + ggtitle("Relationship between Exit Rates and Bounce Rates") + xlab("Bounce Rates") + ylab("Exit Rates") + geom_text(mapping = aes(x = 0.15, y = 0.05, label = "Correlation = 0.913"))
```
There is a strong linear relationship between the Bounce and Exit Rates variables.

#### Correlation matrix 

```{r}
cor(kira_p$Administrative, kira_p$BounceRates)
cor(kira_p$Informational, kira_p$ExitRates)
cor(kira_p$ProductRelated, kira_p$BounceRates)
cor(kira_p$BounceRates, kira_p$ExitRates)
cor(kira_p$Informational, kira_p$BounceRates)
cor(kira_p$Administrative, kira_p$ExitRates)
```

#### Scatter Plots

Let's plot some scatter plots to visualize the relationship between the numerical variables.

```{r}
ggplot(kira_p, aes(Administrative, BounceRates))+
  geom_point()+
  labs(title = "Scatter Plot of Admin page vs Bounce Rates",
       x = "Administrative",
       y = "Bounce Rate")
```

```{r}
ggplot(kira_p, aes(Informational, ExitRates))+
  geom_point()+
  labs(title = "Scatter Plot of Informational page vs Exit Rates",
       x = "Informational",
       y = "Exit Rate")
```

```{r}
ggplot(kira_p, aes(ProductRelated, BounceRates))+
  geom_point()+
  labs(title = "Scatter Plot of Product Related page vs Bounce Rates",
       x = "Product Related",
       y = "Bounce Rate")
```

## Modelling
### Unsupervised learning Techniques

#### K-Means Clustering

K-means clustering is a clustering algorithm that is commonly used for partitioning a given data set into a set of k groups (i.e. k clusters), where k represents the number of groups pre-specified. The algorithm tries to find groups by minimizing the distance between the observations, called local optimal solutions. The distances are measured based on the coordinates of the observations. Let's implement this in our dataset.
First we will process this data for modelling.

```{r}
library(plyr)

kira_p$Month <- factor(kira_p$Month, order = TRUE, levels =c('Feb', 'Mar', 'May', 'June','Jul', 'Aug', 'Sep','Oct', 'Nov','Dec'))
kira_p$Month_num <- mapvalues(kira_p$Month, from = c('Feb', 'Mar', 'May', 'June','Jul', 'Aug', 'Sep','Oct', 'Nov','Dec'), to = c(1,2,3,4,5,6,7,8,9,10))
kira_p$VisitorType <- factor(kira_p$VisitorType, order = TRUE, levels = c('Returning_Visitor', 'Other', 'New_Visitor'))
kira_p$VisitorType_Num <-mapvalues(kira_p$VisitorType, from = c("Returning_Visitor", "Other", "New_Visitor"), to = c(1,2,3))
kira_p$OperatingSystems <- factor(kira_p$OperatingSystems, order = TRUE, levels = c(6,3,7,1,5,2,4,8))
kira_p$Browser <- factor(kira_p$Browser, order = TRUE, levels = c(9,3,6,7,1,2,8,11,4,5,10,13,12))
kira_p$Region <- factor(kira_p$Region, order = TRUE, levels = c(8,6,3,4,7,1,5,2,9))
kira_p$TrafficType <- factor(kira_p$TrafficType, order = TRUE, levels = c(12,15,17,18,13,19,3,9,1,6,4,14,11,10,5,2,20,8,7,16))
kira_p$Weekend <- ifelse(kira_p$Weekend == TRUE, 1, 0)

str(kira_p)
```

Since K Means is an unsupervised learning technique, we won't require the Class label. We will therefore remove attribute, "Revenue" and store it in another variable. 

```{r}
kira_p.new <- kira_p[,c(1,2,3,4,5,6,7,8,9)]
kira_p.class <- kira_p[, "Revenue"]

head(kira_p.new)
```
Previewing our class column

```{r}
head(kira_p.class)
```
```{r}
View(kira_p.new)
```

Normalizing the dataset so that no particular attribute has more impact on our algorithm than others.


```{r}
head(kira_p.new)
```


```{r}
kira_p.new <- scale(kira_p.new)
head(kira_p.new)
```

Finding the optimal value of k

```{r}
# function to compute total within-cluster sum of square 

library(purrr)
wss <- function(k) {
  kmeans(kira_p.new, k, nstart = 10 )$tot.withinss
}

# Compute and plot wss for k = 1 to k = 15
k.values <- 1:10

# extract wss for 2-15 clusters
wss_values <- map_dbl(k.values, wss)

plot(k.values, wss_values,
       type="b", pch = 19, frame = FALSE, 
       xlab="Number of clusters K",
       ylab="Total within-clusters sum of squares")
```

This gives us a k optimal value of 3.
Applying the K-means clustering algorithm with 3 centroids.

```{r}
kmeansresult<- kmeans(kira_p.new,3) 

```

Previewing the no of records in each cluster.
```{r}
kmeansresult$size
```

Getting the value of cluster center datapoint value(3 center for k=3)

```{r}
kmeansresult$centers
```

Getting the cluster vector that shows where the cluster falls.

```{r}
kmeansresult$cluster
```

Visualizing the clustering results.

```{r}
par(mfrow = c(1,2), mar = c(5,4,2,2))

```

Plotting to see how Administrative and Informational points have been distributed in clusters.

```{r}
plot(kira_p.new[,c(1,2)], col = kmeansresult$cluster) 

```
Plotting to see how Page Related and Bounce points have been distributed in clusters.

```{r}
plot(kira_p.new[,c(5,7)], col = kmeansresult$cluster) 

```
Plotting to see how Informational and Exit Rates points have been distributed in clusters.

```{r}
plot(kira_p.new[,c(3,8)], col = kmeansresult$cluster) 

```
```{r}

plot(kira_p.new[,c(5,7)], col = kmeansresult$cluster)
plot(kira_p.new[,c(5,7)], col = kira_p$class)


```

```{r}
table(kmeansresult$cluster, kira_p.class)
```

### Hierarchical Clustering

It's an algorithm that groups similar objects in groups called clusters. It seeks to build a hierarchy of clusters.
There are two types of hierarchical clustering;

* Agglomerative Clustering
* Divisive Clustering

We are going to implement the agglomerative clustering method.
First we use the dist() function, to compute the euclidean distance between observations. 

```{r}
d <- dist(kira_p.new, method = "euclidean")
```

We then perform hierarchical clustering using the Ward's linkage method.

```{r}
res.hc <- hclust(d, method = "ward.D2" )

```

Let's plot the dendrogram.

```{r}
plot(res.hc, cex = 0.6, hang = -1)

```
Using the complete method.

```{r}
res.hc <- hclust(d, method = "complete" )
plot(res.hc, cex = 0.6, hang = -1)

```
Using the single linkage method

```{r}
res.hc <- hclust(d, method = "single" )
plot(res.hc, cex = 0.6, hang = -1)
```

Using the median linkage method.

```{r}
res.hc <- hclust(d, method = "median" )
plot(res.hc, cex = 0.6, hang = -1)
```

## Comparison between the Kmeans and Hierarchical clustering

* Hierarchical clustering is good with small datasets compared to large ones like the one we have here. Therefore K means is a better algorithm for this kind of dataset and analysis.
* Hierarchical clustering requires high space and time complexity so it can't be used when we have huge data like we do here.
* The only advantage Hierarchical clustering has over k means is that you don't need to specify the number of clusters required for the algorithm in the beginning.
* K Means is an easy algorithm to implement compared to Hierarchical clustering. It's only disadvantage is that it can be difficult to predict the number of clusters.

## Conclusions and Recommendations

* The client should use K Means to analyze this dataset since too big for hierarchical clustering, making it hard to get insights from the dendrograms.
* The client should ensure that the website's interface is friendly for users.
* Optimization of the product pages by making the add cart option stand out, having short descriptions, using icons where needed, having a beautiful website that's attractive to the eye and making sure that the shoppers experience is as smooth as possible.
* They could also engage the loyal customers in conversation by offering discounts for friends joining in.